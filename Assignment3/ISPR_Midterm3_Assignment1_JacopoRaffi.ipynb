{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "val_size = 0.2\n",
    "generator = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    \n",
    "    return torch.round(tensor)\n",
    "\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:normalization(tensor, 0, 1))\n",
    "])\n",
    "\n",
    "def add_noise(img_tensor, std=0.35):\n",
    "    return (img_tensor + torch.randn(img_tensor.size(), generator=generator) * std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = torchvision.datasets.MNIST(\"./data\", train=True, transform=img_transform, download=False)\n",
    "test_data = torchvision.datasets.MNIST(\"./data\", train=False, transform=img_transform, download=False)\n",
    "\n",
    "data_size = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(train_data, [int(train_size*data_size), int(val_size*data_size)], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 12000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3071346120>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "j = 69\n",
    "x, _ = train_set[j]\n",
    "ax[0].imshow(x.numpy()[0], cmap='gray')\n",
    "ax[1].imshow(add_noise(x).numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim:int = 784, latent_dim:int = 128):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(input_dim, latent_dim),\n",
    "                                     nn.GELU())\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.Linear(latent_dim, input_dim),\n",
    "                                     nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([64, 1, 28, 28])) that is different to the input size (torch.Size([64, 784])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m input_img \u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m out \u001b[38;5;241m=\u001b[39m model(add_noise(input_img))\n\u001b[0;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ispr/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ispr/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ispr/lib/python3.12/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ispr/lib/python3.12/site-packages/torch/nn/functional.py:3118\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3116\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3121\u001b[0m     )\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([64, 1, 28, 28])) that is different to the input size (torch.Size([64, 784])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for input_img, _ in train_loader:\n",
    "        input_img = input_img.to(device) #TODO: find a way to do this more efficient\n",
    "        out = model(add_noise(input_img))\n",
    "\n",
    "        loss = criterion(out, input_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ispr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
